{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdgmeFvb6jUK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())\n",
        "# print(df.info())\n",
        "# print(df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMMY9mGS7P1X",
        "outputId": "286e763b-b679-43f9-8a8e-57133c2c38a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
            "0    842302         M        17.99         10.38          122.80     1001.0   \n",
            "1    842517         M        20.57         17.77          132.90     1326.0   \n",
            "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
            "3  84348301         M        11.42         20.38           77.58      386.1   \n",
            "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
            "\n",
            "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
            "0          0.11840           0.27760          0.3001              0.14710   \n",
            "1          0.08474           0.07864          0.0869              0.07017   \n",
            "2          0.10960           0.15990          0.1974              0.12790   \n",
            "3          0.14250           0.28390          0.2414              0.10520   \n",
            "4          0.10030           0.13280          0.1980              0.10430   \n",
            "\n",
            "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
            "0  ...          17.33           184.60      2019.0            0.1622   \n",
            "1  ...          23.41           158.80      1956.0            0.1238   \n",
            "2  ...          25.53           152.50      1709.0            0.1444   \n",
            "3  ...          26.50            98.87       567.7            0.2098   \n",
            "4  ...          16.67           152.20      1575.0            0.1374   \n",
            "\n",
            "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
            "0             0.6656           0.7119                0.2654          0.4601   \n",
            "1             0.1866           0.2416                0.1860          0.2750   \n",
            "2             0.4245           0.4504                0.2430          0.3613   \n",
            "3             0.8663           0.6869                0.2575          0.6638   \n",
            "4             0.2050           0.4000                0.1625          0.2364   \n",
            "\n",
            "   fractal_dimension_worst  Unnamed: 32  \n",
            "0                  0.11890          NaN  \n",
            "1                  0.08902          NaN  \n",
            "2                  0.08758          NaN  \n",
            "3                  0.17300          NaN  \n",
            "4                  0.07678          NaN  \n",
            "\n",
            "[5 rows x 33 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping columns that are not needed\n",
        "df = df.drop(columns=['id', 'Unnamed: 32'])\n",
        "\n",
        "#Map the target to binary values: 'M' to 1 (malignant), 'B' to 0 (benign)\n",
        "df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})\n",
        "\n",
        "# Separate features and target datasets\n",
        "X = df.drop(columns=['diagnosis'])\n",
        "y = df['diagnosis']"
      ],
      "metadata": {
        "id": "VtKWvZ1q7WZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=102)\n"
      ],
      "metadata": {
        "id": "VNL3bmDE7jmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "nvK-Efof8YPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Logistic Regression"
      ],
      "metadata": {
        "id": "MzPhLcU28_Wo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-zUVPIdl83Ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#train the model\n",
        "model = LogisticRegression(max_iter=10000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "#Predict and evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Logistic Regression:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hL603ltC8k9G",
        "outputId": "493b48eb-cb34-4eef-cdbe-5aa4f822d515"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98        71\n",
            "           1       0.98      0.95      0.96        43\n",
            "\n",
            "    accuracy                           0.97       114\n",
            "   macro avg       0.97      0.97      0.97       114\n",
            "weighted avg       0.97      0.97      0.97       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Decision Tree Classifier"
      ],
      "metadata": {
        "id": "YoqqV5ns9OXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize and train the model\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Decision Tree Classifier:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5_LfncU8vVb",
        "outputId": "432a0d25-969f-45c6-9f38-33d8300babce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96        71\n",
            "           1       0.93      0.93      0.93        43\n",
            "\n",
            "    accuracy                           0.95       114\n",
            "   macro avg       0.94      0.94      0.94       114\n",
            "weighted avg       0.95      0.95      0.95       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SupportVectorClassifier"
      ],
      "metadata": {
        "id": "tkyfOcSC9ct-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "model = SVC()\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Support Vector Machine (SVM):\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vn1cbnJf9V-J",
        "outputId": "93a607e6-50d2-4c63-aa6b-e35d265d2b77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Support Vector Machine (SVM):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99        71\n",
            "           1       1.00      0.95      0.98        43\n",
            "\n",
            "    accuracy                           0.98       114\n",
            "   macro avg       0.99      0.98      0.98       114\n",
            "weighted avg       0.98      0.98      0.98       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sat Aug 17 21:30:22 2024\n",
        "\n",
        "@author: retro\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"data.csv\")\n",
        "df.head()\n",
        "\n",
        "\n",
        "#Dropping columns that are not needed\n",
        "df = df.drop(columns=['id', 'Unnamed: 32'])\n",
        "\n",
        "#Map the target to binary values: 'M' to 1 (malignant), 'B' to 0 (benign)\n",
        "df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})\n",
        "\n",
        "# Separate features and target datasets\n",
        "X = df.drop(columns=['diagnosis'])\n",
        "y = df['diagnosis']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=200)\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# Define the model hyperparameters\n",
        "params = {\n",
        "    \"solver\": \"lbfgs\",\n",
        "    \"max_iter\": 1000,\n",
        "    \"multi_class\": \"auto\",\n",
        "    \"random_state\": 8888,\n",
        "}\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#train the model\n",
        "model = LogisticRegression(**params)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "#Predict and evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Logistic Regression:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "class_report = classification_report(y_test, y_pred,output_dict= True)\n",
        "\n",
        "#create a metrics which we want to log\n",
        "\n",
        "import mlflow\n",
        "\n",
        "mlflow.set_experiment(\"cancer_data\")\n",
        "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000/\")\n",
        "\n",
        "with mlflow.start_run():\n",
        "    mlflow.log_params(params)\n",
        "    mlflow.log_metrics({\n",
        "        'accuracy': class_report['accuracy'],\n",
        "        'recall_class_0': class_report['0']['recall'],\n",
        "        'recall_class_1': class_report['1']['recall'],\n",
        "        'f1_score': class_report['macro avg']['f1-score']\n",
        "        })\n",
        "    mlflow.sklearn.log_model(model, \"Logistic Regression\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GwQnlu4w9oKG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "outputId": "9f2893f5-6ac7-41c0-eba2-3551bc8f5129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 's' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-b27a2f7dbe5e>\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;34m\"random_state\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m8888\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m }\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 's' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Define a function to handle model training, evaluation, and logging\n",
        "def train_evaluate_log_model(model, model_name, X_train, X_test, y_train, y_test, params):\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict and evaluate\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"{model_name}:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Generate classification report as a dictionary\n",
        "    class_report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    # Log with MLflow\n",
        "    with mlflow.start_run():\n",
        "        mlflow.log_params(params)\n",
        "        mlflow.log_metrics({\n",
        "            'accuracy': class_report['accuracy'],\n",
        "            'recall_class_0': class_report['0']['recall'],\n",
        "            'recall_class_1': class_report['1']['recall'],\n",
        "            'f1_score': class_report['macro avg']['f1-score']\n",
        "        })\n",
        "        mlflow.sklearn.log_model(model, model_name)\n",
        "        print(f\"Model {model_name} logged successfully.\\n\")\n",
        "\n",
        "# Load and preprocess data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=102)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Set up MLflow experiment\n",
        "mlflow.set_experiment(\"cancer_data\")\n",
        "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000/\")\n",
        "\n",
        "# Logistic Regression\n",
        "logistic_params = {\n",
        "    \"solver\": \"lbfgs\",\n",
        "    \"max_iter\": 10000,\n",
        "    \"multi_class\": \"auto\",\n",
        "    \"random_state\": 8888,\n",
        "}\n",
        "logistic_model = LogisticRegression(**logistic_params)\n",
        "train_evaluate_log_model(logistic_model, \"Logistic Regression\", X_train, X_test, y_train, y_test, logistic_params)\n",
        "\n",
        "# Decision Tree Classifier\n",
        "dt_params = {\n",
        "    \"random_state\": 8888,\n",
        "}\n",
        "dt_model = DecisionTreeClassifier(**dt_params)\n",
        "train_evaluate_log_model(dt_model, \"Decision Tree Classifier\", X_train, X_test, y_train, y_test, dt_params)\n",
        "\n",
        "# You can add other models like SVM, RandomForest, and XGBoost similarly:\n",
        "# Example:\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf_params = {\"n_estimators\": 100, \"random_state\": 8888}\n",
        "rf_model = RandomForestClassifier(**rf_params)\n",
        "train_evaluate_log_model(rf_model, \"Random Forest Classifier\", X_train, X_test, y_train, y_test, rf_params)\n",
        "\n",
        "# from xgboost import XGBClassifier\n",
        "# xgb_params = {\"random_state\": 8888}\n",
        "# xgb_model = XGBClassifier(**xgb_params)\n",
        "# train_evaluate_log_model(xgb_model, \"XGBoost Classifier\", X_train, X_test, y_train, y_test, xgb_params)\n"
      ],
      "metadata": {
        "id": "ElRTBR1SbSAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# suppose you are a ML engineer"
      ],
      "metadata": {
        "id": "vO9kxRSKbYqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I am also experiomenting with the preprocessing steps -->\n",
        "\n",
        "# now--> ML engineer--> so that they can also log the preprocessing steps\n",
        "\n"
      ],
      "metadata": {
        "id": "TBlbwL78bc3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Function to log preprocessing steps\n",
        "def log_preprocessing(preprocessing_steps):\n",
        "    mlflow.log_dict(preprocessing_steps, \"preprocessing_steps.json\")\n",
        "\n",
        "# Define a function to handle model training, evaluation, and logging\n",
        "def train_evaluate_log_model(model, model_name, X_train, X_test, y_train, y_test, params, preprocessing_steps):\n",
        "    # Log preprocessing steps\n",
        "    log_preprocessing(preprocessing_steps)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict and evaluate\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"{model_name}:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Generate classification report as a dictionary\n",
        "    class_report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    # Log with MLflow\n",
        "    with mlflow.start_run():\n",
        "        mlflow.log_params(params)\n",
        "        mlflow.log_metrics({\n",
        "            'accuracy': class_report['accuracy'],\n",
        "            'recall_class_0': class_report['0']['recall'],\n",
        "            'recall_class_1': class_report['1']['recall'],\n",
        "            'f1_score': class_report['macro avg']['f1-score']\n",
        "        })\n",
        "        mlflow.sklearn.log_model(model, model_name)\n",
        "        print(f\"Model {model_name} logged successfully.\\n\")\n",
        "\n",
        "# Load and preprocess data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=102)\n",
        "\n",
        "# Preprocessing steps\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Record preprocessing steps\n",
        "preprocessing_steps = {\n",
        "    \"scaling\": {\n",
        "        \"method\": \"StandardScaler\",\n",
        "        \"mean\": scaler.mean_.tolist(),  # mean used for scaling\n",
        "        \"var\": scaler.var_.tolist(),    # variance used for scaling\n",
        "    },\n",
        "    \"train_test_split\": {\n",
        "        \"test_size\": 0.2,\n",
        "        \"random_state\": 102\n",
        "    }\n",
        "}\n",
        "\n",
        "# Set up MLflow experiment\n",
        "mlflow.set_experiment(\"cancer_data\")\n",
        "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000/\")\n",
        "\n",
        "# Logistic Regression\n",
        "logistic_params = {\n",
        "    \"solver\": \"lbfgs\",\n",
        "    \"max_iter\": 10000,\n",
        "    \"multi_class\": \"auto\",\n",
        "    \"random_state\": 8888,\n",
        "}\n",
        "logistic_model = LogisticRegression(**logistic_params)\n",
        "train_evaluate_log_model(logistic_model, \"Logistic Regression\", X_train, X_test, y_train, y_test, logistic_params, preprocessing_steps)\n",
        "\n",
        "# Decision Tree Classifier\n",
        "dt_params = {\n",
        "    \"random_state\": 8888,\n",
        "}\n",
        "dt_model = DecisionTreeClassifier(**dt_params)\n",
        "train_evaluate_log_model(dt_model, \"Decision Tree Classifier\", X_train, X_test, y_train, y_test, dt_params, preprocessing_steps)\n",
        "\n",
        "# You can add other models like SVM, RandomForest, and XGBoost similarly:\n",
        "# Example:\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# rf_params = {\"n_estimators\": 100, \"random_st\n"
      ],
      "metadata": {
        "id": "K-SoM814cGZF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}