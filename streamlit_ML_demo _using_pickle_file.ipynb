{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13KHCNWjRM45",
        "outputId": "94d994b6-b3e0-4c33-9ae2-acc38d5dbe62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset\n",
        "housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
        "X = housing.data[[\"GrLivArea\", \"YearBuilt\"]]  # Select a few features\n",
        "y = housing.target\n",
        "\n",
        "# Train model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Streamlit app\n",
        "st.title('Ames Housing Price Prediction')\n",
        "\n",
        "GrLivArea = st.number_input('Above grade living area in square feet', value=1500)\n",
        "YearBuilt = st.number_input('Original construction date', value=2000)\n",
        "\n",
        "input_data = pd.DataFrame({'GrLivArea': [GrLivArea], 'YearBuilt': [YearBuilt]})\n",
        "\n",
        "if st.button('Predict'):\n",
        "    prediction = model.predict(input_data)\n",
        "    st.write(f'Predicted House Price: ${prediction[0]:.2f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streamlit_iris.py\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sun Aug 11 22:09:18 2024\n",
        "\n",
        "@author: retro\n",
        "\"\"\"\n",
        "\n",
        "# streamlit_app.py\n",
        "\n",
        "import streamlit as st\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# Load the trained model\n",
        "with open('iris_model.pkl', 'rb') as file:\n",
        "    model = pickle.load(file)\n",
        "\n",
        "# Streamlit app title\n",
        "st.title(\"Iris Flower Prediction\")\n",
        "\n",
        "# User input for model features\n",
        "st.write(\"## Input Features\")\n",
        "sepal_length = st.slider('Sepal Length (cm)', 4.0, 8.0, 5.0)\n",
        "sepal_width = st.slider('Sepal Width (cm)', 2.0, 4.5, 3.0)\n",
        "petal_length = st.slider('Petal Length (cm)', 1.0, 7.0, 4.0)\n",
        "petal_width = st.slider('Petal Width (cm)', 0.1, 2.5, 1.0)\n",
        "\n",
        "# Prepare the input data\n",
        "input_data = np.array([[sepal_length, sepal_width, petal_length, petal_width]])\n",
        "\n",
        "# Make prediction\n",
        "prediction = model.predict(input_data)\n",
        "prediction_proba = model.predict_proba(input_data)\n",
        "\n",
        "# Output the results\n",
        "st.write(\"## Prediction\")\n",
        "st.write(f\"The predicted class is: {prediction[0]} (0=setosa, 1=versicolor, 2=virginica)\")\n",
        "st.write(\"## Prediction Probability\")\n",
        "st.write(f\"Setosa: {prediction_proba[0][0]*100:.2f}%\")\n",
        "st.write(f\"Versicolor: {prediction_proba[0][1]*100:.2f}%\")\n",
        "st.write(f\"Virginica: {prediction_proba[0][2]*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7m6i4UKPVCo0",
        "outputId": "13861a62-e39a-4076-e84b-f4ae8c7f1781"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing streamlit_iris.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ml_iris.py\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sun Aug 11 22:06:47 2024\n",
        "\n",
        "@author: retro\n",
        "\"\"\"\n",
        "# train_model.py\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pickle\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train a RandomForest model\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Save the trained model to a file\n",
        "with open('iris_model.pkl', 'wb') as file:\n",
        "    pickle.dump(model, file)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKwYmWMMVKeX",
        "outputId": "8545b9ad-020c-4027-92e7-f5795e7a09bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing ml_iris.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mainirisflask.py\n",
        "\n",
        "from flask import Flask, request, jsonify\n",
        "# flas--> web server, request--> request , jsonify-->\n",
        "import pickle\n",
        "\n",
        "# use the pre-trained model\n",
        "import numpy as np\n",
        "\n",
        "# Load the model from the pickle file\n",
        "with open('model1.pkl', 'rb') as file:\n",
        "    model = pickle.load(file)\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return \"Flask app is running!\"\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    try:\n",
        "        data = request.json  # Expecting JSON input with features\n",
        "        if 'features' not in data:\n",
        "            return jsonify({'error': 'Missing \"features\" in request data'}), 400\n",
        "        features = np.array(data['features'])  # Convert input to numpy array\n",
        "        prediction = model.predict([features])  # Make prediction\n",
        "        return jsonify({'prediction': int(prediction[0])})  # Return prediction as JSON\n",
        "    except Exception as e:\n",
        "        return jsonify({'error': str(e)}), 500\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LQPcOKxlrWF",
        "outputId": "d344a1c1-394a-4989-ce76-56b0c06dbfa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mainirisflask.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile flaskmodeliris.py\n",
        "\n",
        "# Import necessary libraries\n",
        "import pickle\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Load the dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model1 = RandomForestClassifier()\n",
        "model1.fit(X_train, y_train)\n",
        "\n",
        "# Save the trained model as a pickle file\n",
        "with open('model1.pkl', 'wb') as file:\n",
        "    pickle.dump(model1, file)\n"
      ],
      "metadata": {
        "id": "oofczdqulzv9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}